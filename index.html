<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ðŸ“š Local LLM Literature Reviewer</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">
    <style>
        /* Custom scrollbar */
        ::-webkit-scrollbar { width: 8px; height: 8px; }
        ::-webkit-scrollbar-track { background: #1e293b; }
        ::-webkit-scrollbar-thumb { background: #475569; border-radius: 4px; }
        ::-webkit-scrollbar-thumb:hover { background: #64748b; }
        
        /* Animations */
        @keyframes pulse-glow {
            0%, 100% { box-shadow: 0 0 5px rgba(59, 130, 246, 0.5); }
            50% { box-shadow: 0 0 20px rgba(59, 130, 246, 0.8); }
        }
        .loading-glow { animation: pulse-glow 2s ease-in-out infinite; }
        
        @keyframes typing {
            0%, 60%, 100% { opacity: 0.3; }
            30% { opacity: 1; }
        }
        .typing-dot { animation: typing 1.4s infinite; }
        .typing-dot:nth-child(2) { animation-delay: 0.2s; }
        .typing-dot:nth-child(3) { animation-delay: 0.4s; }
        
        /* Markdown styles */
        .prose h1 { font-size: 1.5em; font-weight: bold; margin: 0.5em 0; }
        .prose h2 { font-size: 1.3em; font-weight: bold; margin: 0.5em 0; }
        .prose h3 { font-size: 1.1em; font-weight: bold; margin: 0.5em 0; }
        .prose p { margin: 0.5em 0; }
        .prose ul, .prose ol { margin: 0.5em 0; padding-left: 1.5em; }
        .prose li { margin: 0.25em 0; }
        .prose code { background: #374151; padding: 0.1em 0.3em; border-radius: 3px; font-size: 0.9em; }
        .prose pre { background: #1e293b; padding: 1em; border-radius: 8px; overflow-x: auto; margin: 0.5em 0; }
        .prose blockquote { border-left: 3px solid #3b82f6; padding-left: 1em; margin: 0.5em 0; opacity: 0.9; }
    </style>
</head>
<body class="bg-slate-900 text-slate-100 min-h-screen">
    <!-- Header -->
    <header class="bg-slate-800 border-b border-slate-700 px-6 py-4">
        <div class="max-w-7xl mx-auto flex items-center justify-between">
            <div class="flex items-center gap-3">
                <div class="text-3xl">ðŸ“š</div>
                <div>
                    <h1 class="text-xl font-bold text-white">Local LLM Literature Reviewer</h1>
                    <p class="text-sm text-slate-400">100% Private â€¢ Browser-Based â€¢ No Cloud</p>
                </div>
            </div>
            <div class="flex items-center gap-4">
                <a href="dashboard.html" class="flex items-center gap-2 px-3 py-1.5 bg-purple-600/20 text-purple-400 rounded-lg hover:bg-purple-600/30 transition-colors text-sm">
                    <i class="fas fa-chart-line"></i>
                    <span>Dashboard</span>
                </a>
                <div id="webgpu-status" class="flex items-center gap-2 text-sm">
                    <span class="w-2 h-2 rounded-full bg-yellow-500"></span>
                    <span class="text-slate-400">Checking WebGPU...</span>
                </div>
            </div>
        </div>
    </header>

    <main class="max-w-7xl mx-auto p-6">
        <div class="grid grid-cols-1 lg:grid-cols-3 gap-6">
            <!-- Left Panel: Documents & Memory -->
            <div class="lg:col-span-1 space-y-6">
                <!-- PDF Upload Zone -->
                <div class="bg-slate-800 rounded-xl border border-slate-700 p-4">
                    <h2 class="text-lg font-semibold mb-3 flex items-center gap-2">
                        <i class="fas fa-file-pdf text-red-400"></i>
                        Document Ingestion
                    </h2>
                    <div id="drop-zone" 
                         class="border-2 border-dashed border-slate-600 rounded-lg p-6 text-center cursor-pointer hover:border-blue-500 hover:bg-slate-700/50 transition-all">
                        <i class="fas fa-cloud-upload-alt text-4xl text-slate-500 mb-3"></i>
                        <p class="text-slate-400">Drag & drop PDF files here</p>
                        <p class="text-sm text-slate-500 mt-1">or click to browse</p>
                        <input type="file" id="file-input" multiple accept=".pdf" class="hidden">
                    </div>
                    
                    <!-- Processing Status -->
                    <div id="processing-status" class="hidden mt-4">
                        <div class="flex items-center gap-2 text-sm text-blue-400">
                            <i class="fas fa-spinner fa-spin"></i>
                            <span id="processing-text">Processing...</span>
                        </div>
                        <div class="w-full bg-slate-700 rounded-full h-2 mt-2">
                            <div id="processing-bar" class="bg-blue-500 h-2 rounded-full transition-all" style="width: 0%"></div>
                        </div>
                    </div>
                </div>

                <!-- Memory Bank -->
                <div class="bg-slate-800 rounded-xl border border-slate-700 p-4">
                    <h2 class="text-lg font-semibold mb-3 flex items-center gap-2">
                        <i class="fas fa-database text-purple-400"></i>
                        Memory Bank
                    </h2>
                    <div class="grid grid-cols-2 gap-3 mb-4">
                        <div class="bg-slate-700/50 rounded-lg p-3 text-center">
                            <div id="doc-count" class="text-2xl font-bold text-blue-400">0</div>
                            <div class="text-xs text-slate-400">Documents</div>
                        </div>
                        <div class="bg-slate-700/50 rounded-lg p-3 text-center">
                            <div id="chunk-count" class="text-2xl font-bold text-green-400">0</div>
                            <div class="text-xs text-slate-400">Chunks</div>
                        </div>
                        <div class="bg-slate-700/50 rounded-lg p-3 text-center">
                            <div id="vector-count" class="text-2xl font-bold text-purple-400">0</div>
                            <div class="text-xs text-slate-400">Vectors</div>
                        </div>
                        <div class="bg-slate-700/50 rounded-lg p-3 text-center">
                            <div id="storage-size" class="text-2xl font-bold text-orange-400">0</div>
                            <div class="text-xs text-slate-400">KB Used</div>
                        </div>
                    </div>
                    
                    <!-- Document List -->
                    <div id="document-list" class="space-y-2 max-h-48 overflow-y-auto">
                        <p class="text-sm text-slate-500 italic">No documents loaded yet</p>
                    </div>
                    
                    <button id="clear-memory" class="w-full mt-4 py-2 px-4 bg-red-600/20 text-red-400 rounded-lg hover:bg-red-600/30 transition-colors text-sm">
                        <i class="fas fa-trash mr-2"></i>Clear All Memory
                    </button>
                </div>

                <!-- System Controls -->
                <div class="bg-slate-800 rounded-xl border border-slate-700 p-4">
                    <h2 class="text-lg font-semibold mb-3 flex items-center gap-2">
                        <i class="fas fa-sliders-h text-cyan-400"></i>
                        System Controls
                    </h2>
                    
                    <div class="space-y-4">
                        <!-- Temperature -->
                        <div>
                            <label class="flex items-center justify-between text-sm text-slate-400 mb-1">
                                <span>Temperature</span>
                                <span id="temp-value" class="text-cyan-400">0.7</span>
                            </label>
                            <input type="range" id="temperature" min="0" max="1" step="0.1" value="0.7"
                                   class="w-full h-2 bg-slate-700 rounded-lg appearance-none cursor-pointer">
                        </div>
                        
                        <!-- Top K Chunks -->
                        <div>
                            <label class="flex items-center justify-between text-sm text-slate-400 mb-1">
                                <span>Top K Chunks</span>
                                <span id="topk-value" class="text-cyan-400">5</span>
                            </label>
                            <input type="range" id="top-k" min="1" max="10" step="1" value="5"
                                   class="w-full h-2 bg-slate-700 rounded-lg appearance-none cursor-pointer">
                        </div>
                        
                        <!-- TTS Toggle -->
                        <div class="flex items-center justify-between">
                            <label class="text-sm text-slate-400 flex items-center gap-2">
                                <i class="fas fa-volume-up"></i>
                                <span>Text-to-Speech</span>
                            </label>
                            <button id="tts-toggle" class="relative w-12 h-6 bg-green-600 rounded-full transition-colors">
                                <span class="absolute left-1 top-1 w-4 h-4 bg-white rounded-full transition-transform transform translate-x-6"></span>
                            </button>
                        </div>
                        
                        <!-- System Prompt -->
                        <div>
                            <label class="text-sm text-slate-400 mb-1 block">System Prompt</label>
                            <textarea id="system-prompt" rows="4"
                                      class="w-full bg-slate-700 border border-slate-600 rounded-lg p-2 text-sm text-slate-200 resize-none focus:outline-none focus:border-blue-500">You are an expert Academic Researcher and Literature Review specialist. Your role is to:
1. Analyze and synthesize information from research papers
2. Identify key themes, methodologies, and findings
3. Compare and contrast different papers' perspectives
4. Generate structured, professional literature reviews
5. Always cite the specific papers you reference

Be precise, academic, and thorough in your analysis.</textarea>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Right Panel: Chat Interface -->
            <div class="lg:col-span-2 flex flex-col bg-slate-800 rounded-xl border border-slate-700 overflow-hidden" style="height: calc(100vh - 180px);">
                <!-- Model Loading Status -->
                <div id="model-status" class="bg-slate-700/50 px-4 py-3 border-b border-slate-700">
                    <div class="flex items-center justify-between">
                        <div class="flex items-center gap-3">
                            <div id="model-indicator" class="w-3 h-3 rounded-full bg-yellow-500"></div>
                            <span id="model-text" class="text-sm text-slate-300">Loading models...</span>
                        </div>
                        <div class="flex items-center gap-2">
                            <button id="load-models-btn" class="px-3 py-1 bg-blue-600 text-white text-sm rounded hover:bg-blue-700 transition-colors">
                                <i class="fas fa-rocket mr-1"></i>Load Models
                            </button>
                        </div>
                    </div>
                    <div id="model-progress" class="hidden mt-2">
                        <div class="flex justify-between text-xs text-slate-400 mb-1">
                            <span id="model-progress-text">Initializing...</span>
                            <span id="model-progress-percent">0%</span>
                        </div>
                        <div class="w-full bg-slate-600 rounded-full h-1.5">
                            <div id="model-progress-bar" class="bg-blue-500 h-1.5 rounded-full transition-all" style="width: 0%"></div>
                        </div>
                    </div>
                </div>

                <!-- Chat Messages -->
                <div id="chat-messages" class="flex-1 overflow-y-auto p-4 space-y-4">
                    <!-- Welcome Message -->
                    <div class="flex gap-3">
                        <div class="w-8 h-8 rounded-full bg-gradient-to-br from-purple-500 to-blue-500 flex items-center justify-center flex-shrink-0">
                            <i class="fas fa-robot text-white text-sm"></i>
                        </div>
                        <div class="bg-slate-700/50 rounded-lg rounded-tl-none p-4 max-w-2xl">
                            <p class="text-slate-200">Welcome to the <strong>Local LLM Literature Reviewer</strong>! ðŸ“š</p>
                            <p class="text-slate-300 mt-2">I run entirely in your browser - no data leaves your device. Here's how to get started:</p>
                            <ol class="text-slate-300 mt-2 ml-4 list-decimal space-y-1">
                                <li>Click <strong>"Load Models"</strong> to initialize the AI (requires WebGPU)</li>
                                <li>Upload your research PDFs using the drop zone</li>
                                <li>Ask me questions or request a literature review!</li>
                            </ol>
                            <p class="text-slate-400 text-sm mt-3 italic">Tip: Try "Generate a literature review of the uploaded papers"</p>
                        </div>
                    </div>
                </div>

                <!-- Context Panel (shows retrieved chunks) -->
                <div id="context-panel" class="hidden border-t border-slate-700 bg-slate-800/50 max-h-48 overflow-y-auto">
                    <div class="p-3">
                        <div class="flex items-center justify-between mb-2">
                            <span class="text-sm font-medium text-slate-400">
                                <i class="fas fa-quote-left mr-1"></i>Retrieved Context
                            </span>
                            <button id="close-context" class="text-slate-500 hover:text-slate-300">
                                <i class="fas fa-times"></i>
                            </button>
                        </div>
                        <div id="context-chunks" class="space-y-2"></div>
                    </div>
                </div>

                <!-- Input Area -->
                <div class="border-t border-slate-700 p-4">
                    <div class="flex gap-3">
                        <div class="flex-1 relative">
                            <textarea id="user-input" 
                                      placeholder="Ask about your papers or request a literature review..."
                                      rows="2"
                                      class="w-full bg-slate-700 border border-slate-600 rounded-lg px-4 py-3 pr-12 text-slate-200 resize-none focus:outline-none focus:border-blue-500 placeholder-slate-500"
                                      disabled></textarea>
                            <button id="voice-btn" class="absolute right-3 top-1/2 -translate-y-1/2 text-slate-500 hover:text-blue-400 transition-colors" title="Voice Input">
                                <i class="fas fa-microphone text-lg"></i>
                            </button>
                        </div>
                        <button id="send-btn" 
                                class="px-6 py-3 bg-blue-600 text-white rounded-lg hover:bg-blue-700 disabled:opacity-50 disabled:cursor-not-allowed transition-colors"
                                disabled>
                            <i class="fas fa-paper-plane"></i>
                        </button>
                    </div>
                    <div class="flex items-center justify-between mt-2 text-xs text-slate-500">
                        <span>Press Enter to send, Shift+Enter for new line</span>
                        <span id="char-count">0 / 2000</span>
                    </div>
                </div>
            </div>
        </div>
    </main>

    <!-- Audio Feedback -->
    <div id="voice-indicator" class="hidden fixed bottom-24 right-8 bg-red-600 text-white px-4 py-2 rounded-full flex items-center gap-2 shadow-lg">
        <i class="fas fa-microphone"></i>
        <span>Listening...</span>
        <div class="flex gap-1">
            <div class="w-1 h-4 bg-white rounded animate-pulse"></div>
            <div class="w-1 h-6 bg-white rounded animate-pulse" style="animation-delay: 0.1s"></div>
            <div class="w-1 h-3 bg-white rounded animate-pulse" style="animation-delay: 0.2s"></div>
        </div>
    </div>

    <!-- Scripts -->
    <script type="module">
        // ============================================
        // CONFIGURATION & STATE
        // ============================================
        const CONFIG = {
            CHUNK_SIZE: 500,
            CHUNK_OVERLAP: 100,
            EMBEDDING_MODEL: 'Xenova/all-MiniLM-L6-v2',
            WHISPER_MODEL: 'Xenova/whisper-tiny',
            LLM_MODEL: 'Llama-3.2-1B-Instruct-q4f16_1-MLC',
            TOP_K: 5,
            TEMPERATURE: 0.7,
            TTS_ENABLED: true,
            SELF_EVAL_ENABLED: true,
            STORAGE_KEY: 'lit-reviewer-metrics'
        };

        const state = {
            vectorStore: [],
            documents: [],
            chatHistory: [],
            embeddingPipeline: null,
            whisperPipeline: null,
            pipelineFactory: null,
            llmEngine: null,
            isProcessing: false,
            isGenerating: false,
            isTranscribing: false,
            modelsLoaded: false,
            // Metrics tracking
            sessionId: crypto.randomUUID(),
            sessionStartTime: Date.now(),
            currentQueryMetrics: null,
            queriesMetrics: []
        };

        // ============================================
        // FIREBASE CONFIGURATION
        // ============================================
        import { initializeApp } from "https://www.gstatic.com/firebasejs/11.7.0/firebase-app.js";
        import { getDatabase, ref, push, set, update, onValue, get } from "https://www.gstatic.com/firebasejs/11.7.0/firebase-database.js";
        
        const firebaseConfig = {
            apiKey: "AIzaSyAF7oeRHdlr9HjMWg0exrCA35ziSXbH06E",
            authDomain: "aicgllm.firebaseapp.com",
            databaseURL: "https://aicgllm-default-rtdb.europe-west1.firebasedatabase.app",
            projectId: "aicgllm",
            storageBucket: "aicgllm.firebasestorage.app",
            messagingSenderId: "753346448022",
            appId: "1:753346448022:web:e98bf4234a15047107d0b7",
            measurementId: "G-XSH19F0QVY"
        };
        
        // Initialize Firebase
        const firebaseApp = initializeApp(firebaseConfig);
        const database = getDatabase(firebaseApp);
        
        // ============================================
        // METRICS & PERSISTENCE (Firebase + localStorage fallback)
        // ============================================
        
        let firebaseSessionRef = null;
        
        // Initialize metrics storage
        async function initMetricsStorage() {
            try {
                // Create a new session reference in Firebase
                const sessionsRef = ref(database, 'sessions');
                firebaseSessionRef = push(sessionsRef);
                
                // Initialize session data
                const sessionData = {
                    sessionId: state.sessionId,
                    timestamp: state.sessionStartTime,
                    userAgent: navigator.userAgent.substring(0, 100),
                    documentsProcessed: 0,
                    totalChunks: 0,
                    queries: {}
                };
                
                await set(firebaseSessionRef, sessionData);
                console.log('âœ… Firebase connected - Session:', state.sessionId);
                
                // Update global stats
                await incrementGlobalStat('totalSessions', 1);
                
            } catch (e) {
                console.warn('âš ï¸ Firebase unavailable, using localStorage fallback:', e.message);
                initLocalStorage();
            }
        }
        
        // Fallback to localStorage
        function initLocalStorage() {
            const existing = localStorage.getItem(CONFIG.STORAGE_KEY);
            if (!existing) {
                const initial = {
                    sessions: [],
                    aggregates: getEmptyAggregates()
                };
                localStorage.setItem(CONFIG.STORAGE_KEY, JSON.stringify(initial));
            }
        }
        
        function getEmptyAggregates() {
            return {
                totalSessions: 0,
                totalQueries: 0,
                totalThumbsUp: 0,
                totalThumbsDown: 0,
                avgTTFT: 0,
                avgTPS: 0,
                avgTopSimilarity: 0,
                avgSelfEvalFaithfulness: 0,
                avgSelfEvalRelevance: 0,
                avgSelfEvalCoherence: 0
            };
        }
        
        // Increment a global statistic
        async function incrementGlobalStat(statName, value) {
            try {
                const statRef = ref(database, `aggregates/${statName}`);
                const snapshot = await get(statRef);
                const currentValue = snapshot.exists() ? snapshot.val() : 0;
                await set(statRef, currentValue + value);
            } catch (e) {
                console.error('Error updating global stat:', e);
            }
        }
        
        // Update running averages
        async function updateRunningAverage(statName, newValue, countStatName) {
            try {
                const avgRef = ref(database, `aggregates/${statName}`);
                const countRef = ref(database, `aggregates/${countStatName}`);
                
                const [avgSnap, countSnap] = await Promise.all([get(avgRef), get(countRef)]);
                
                const currentAvg = avgSnap.exists() ? avgSnap.val() : 0;
                const count = countSnap.exists() ? countSnap.val() : 0;
                
                // Calculate new running average
                const newAvg = count > 0 
                    ? ((currentAvg * count) + newValue) / (count + 1)
                    : newValue;
                
                await set(avgRef, Math.round(newAvg * 1000) / 1000);
            } catch (e) {
                console.error('Error updating running average:', e);
            }
        }
        
        // Save query metrics to Firebase
        async function saveQueryMetrics(queryMetrics) {
            try {
                if (firebaseSessionRef) {
                    // Save to Firebase
                    const queryRef = ref(database, `sessions/${firebaseSessionRef.key}/queries/${queryMetrics.id}`);
                    await set(queryRef, queryMetrics);
                    
                    // Update global aggregates
                    await incrementGlobalStat('totalQueries', 1);
                    
                    if (queryMetrics.generation?.ttftMs) {
                        await updateRunningAverage('avgTTFT', queryMetrics.generation.ttftMs, 'totalQueries');
                    }
                    if (queryMetrics.generation?.tokensPerSecond) {
                        await updateRunningAverage('avgTPS', queryMetrics.generation.tokensPerSecond, 'totalQueries');
                    }
                    if (queryMetrics.retrieval?.topSimilarity) {
                        await updateRunningAverage('avgTopSimilarity', queryMetrics.retrieval.topSimilarity, 'totalQueries');
                    }
                    
                    // Update session info
                    await update(ref(database, `sessions/${firebaseSessionRef.key}`), {
                        documentsProcessed: state.documents.length,
                        totalChunks: state.vectorStore.length,
                        lastActivity: Date.now()
                    });
                } else {
                    // Fallback to localStorage
                    saveToLocalStorage(queryMetrics);
                }
            } catch (e) {
                console.error('Error saving to Firebase, falling back to localStorage:', e);
                saveToLocalStorage(queryMetrics);
            }
        }
        
        // Save session metrics (called after each query)
        function saveSessionMetrics() {
            // This is now handled incrementally by saveQueryMetrics
            // Keep for compatibility with existing code
        }
        
        // Fallback localStorage save
        function saveToLocalStorage(queryMetrics) {
            try {
                const data = JSON.parse(localStorage.getItem(CONFIG.STORAGE_KEY) || '{"sessions":[],"aggregates":{}}');
                
                let session = data.sessions.find(s => s.sessionId === state.sessionId);
                if (!session) {
                    session = {
                        sessionId: state.sessionId,
                        timestamp: state.sessionStartTime,
                        userAgent: navigator.userAgent.substring(0, 100),
                        documentsProcessed: state.documents.length,
                        totalChunks: state.vectorStore.length,
                        queries: []
                    };
                    data.sessions.push(session);
                }
                
                session.queries.push(queryMetrics);
                session.documentsProcessed = state.documents.length;
                session.totalChunks = state.vectorStore.length;
                
                // Recalculate aggregates
                updateLocalAggregates(data);
                
                // Keep only last 100 sessions
                if (data.sessions.length > 100) {
                    data.sessions = data.sessions.slice(-100);
                }
                
                localStorage.setItem(CONFIG.STORAGE_KEY, JSON.stringify(data));
            } catch (e) {
                console.error('Error saving to localStorage:', e);
            }
        }
        
        // Update local aggregates
        function updateLocalAggregates(data) {
            const allQueries = data.sessions.flatMap(s => s.queries || []);
            const queriesWithSelfEval = allQueries.filter(q => q.selfEval);
            
            data.aggregates = {
                totalSessions: data.sessions.length,
                totalQueries: allQueries.length,
                totalThumbsUp: allQueries.filter(q => q.feedback?.userVote === 'up').length,
                totalThumbsDown: allQueries.filter(q => q.feedback?.userVote === 'down').length,
                avgTTFT: allQueries.length > 0 
                    ? Math.round(allQueries.reduce((sum, q) => sum + (q.generation?.ttftMs || 0), 0) / allQueries.length)
                    : 0,
                avgTPS: allQueries.length > 0
                    ? Math.round(allQueries.reduce((sum, q) => sum + (q.generation?.tokensPerSecond || 0), 0) / allQueries.length)
                    : 0,
                avgTopSimilarity: allQueries.length > 0
                    ? (allQueries.reduce((sum, q) => sum + (q.retrieval?.topSimilarity || 0), 0) / allQueries.length).toFixed(3)
                    : 0,
                avgSelfEvalFaithfulness: queriesWithSelfEval.length > 0
                    ? (queriesWithSelfEval.reduce((sum, q) => sum + (q.selfEval?.faithfulness || 0), 0) / queriesWithSelfEval.length).toFixed(1)
                    : 0,
                avgSelfEvalRelevance: queriesWithSelfEval.length > 0
                    ? (queriesWithSelfEval.reduce((sum, q) => sum + (q.selfEval?.relevance || 0), 0) / queriesWithSelfEval.length).toFixed(1)
                    : 0,
                avgSelfEvalCoherence: queriesWithSelfEval.length > 0
                    ? (queriesWithSelfEval.reduce((sum, q) => sum + (q.selfEval?.coherence || 0), 0) / queriesWithSelfEval.length).toFixed(1)
                    : 0
            };
        }
        
        // Record user feedback for a query
        async function recordFeedback(queryId, vote) {
            const query = state.queriesMetrics.find(q => q.id === queryId);
            if (query) {
                query.feedback = { userVote: vote, timestamp: Date.now() };
                
                try {
                    if (firebaseSessionRef) {
                        // Update in Firebase
                        const feedbackRef = ref(database, `sessions/${firebaseSessionRef.key}/queries/${queryId}/feedback`);
                        await set(feedbackRef, query.feedback);
                        
                        // Update global feedback counts
                        if (vote === 'up') {
                            await incrementGlobalStat('totalThumbsUp', 1);
                        } else {
                            await incrementGlobalStat('totalThumbsDown', 1);
                        }
                    } else {
                        saveToLocalStorage(query);
                    }
                } catch (e) {
                    console.error('Error saving feedback:', e);
                }
            }
        }
        
        // Run self-evaluation using the LLM
        async function runSelfEvaluation(queryId, userQuery, context, response) {
            if (!CONFIG.SELF_EVAL_ENABLED || !state.llmEngine) return;
            
            try {
                const evalPrompt = `Rate this response on a scale of 1-5 for each criterion. Respond ONLY with JSON, no other text.

Question: "${userQuery.substring(0, 200)}"

Context provided: "${context.substring(0, 500)}..."

Response given: "${response.substring(0, 500)}..."

Rate:
- faithfulness: Does the response only use information from the context? (1=hallucinated, 5=fully grounded)
- relevance: Does the response answer the question? (1=off-topic, 5=perfectly relevant)  
- coherence: Is the response well-structured and logical? (1=confusing, 5=clear)

JSON format: {"faithfulness": X, "relevance": X, "coherence": X}`;

                const evalResponse = await state.llmEngine.chat.completions.create({
                    messages: [{ role: 'user', content: evalPrompt }],
                    temperature: 0.1,
                    max_tokens: 100
                });
                
                const evalText = evalResponse.choices[0]?.message?.content || '';
                
                // Parse JSON from response
                const jsonMatch = evalText.match(/\{[\s\S]*\}/);
                if (jsonMatch) {
                    const evalResult = JSON.parse(jsonMatch[0]);
                    
                    // Validate and clamp values
                    const clamp = (v) => Math.max(1, Math.min(5, parseInt(v) || 3));
                    
                    const query = state.queriesMetrics.find(q => q.id === queryId);
                    if (query) {
                        query.selfEval = {
                            faithfulness: clamp(evalResult.faithfulness),
                            relevance: clamp(evalResult.relevance),
                            coherence: clamp(evalResult.coherence),
                            timestamp: Date.now()
                        };
                        
                        // Save to Firebase
                        if (firebaseSessionRef) {
                            const selfEvalRef = ref(database, `sessions/${firebaseSessionRef.key}/queries/${queryId}/selfEval`);
                            await set(selfEvalRef, query.selfEval);
                            
                            // Update running averages
                            await updateRunningAverage('avgSelfEvalFaithfulness', query.selfEval.faithfulness, 'totalSelfEvals');
                            await updateRunningAverage('avgSelfEvalRelevance', query.selfEval.relevance, 'totalSelfEvals');
                            await updateRunningAverage('avgSelfEvalCoherence', query.selfEval.coherence, 'totalSelfEvals');
                            await incrementGlobalStat('totalSelfEvals', 1);
                        }
                    }
                }
            } catch (e) {
                console.error('Self-evaluation error:', e);
            }
        }

        // ============================================
        // UTILITY FUNCTIONS
        // ============================================
        
        // Cosine Similarity - Optimized for normalized vectors (just dot product)
        // Since we use normalize: true in embeddings, ||A|| = ||B|| = 1
        function cosineSimilarity(vecA, vecB) {
            const len = vecA.length;
            if (len !== vecB.length) return 0;
            
            let dot = 0;
            // Unroll loop for better performance
            const remainder = len % 4;
            let i = 0;
            
            // Process 4 elements at a time
            for (; i < len - remainder; i += 4) {
                dot += vecA[i] * vecB[i] +
                       vecA[i+1] * vecB[i+1] +
                       vecA[i+2] * vecB[i+2] +
                       vecA[i+3] * vecB[i+3];
            }
            
            // Handle remaining elements
            for (; i < len; i++) {
                dot += vecA[i] * vecB[i];
            }
            
            return dot;
        }

        // Text chunking with sliding window
        function chunkText(text, chunkSize = CONFIG.CHUNK_SIZE, overlap = CONFIG.CHUNK_OVERLAP) {
            const chunks = [];
            const cleanText = text.replace(/\s+/g, ' ').trim();
            
            if (cleanText.length <= chunkSize) {
                return [cleanText];
            }
            
            let start = 0;
            while (start < cleanText.length) {
                const end = Math.min(start + chunkSize, cleanText.length);
                const chunk = cleanText.slice(start, end);
                
                if (chunk.trim().length > 50) { // Minimum meaningful chunk
                    chunks.push(chunk.trim());
                }
                
                start += chunkSize - overlap;
            }
            
            return chunks;
        }

        // Format bytes to human readable
        function formatBytes(bytes) {
            if (bytes === 0) return '0';
            const k = 1024;
            return Math.round(bytes / k);
        }

        // Simple markdown to HTML
        function markdownToHtml(text) {
            return text
                .replace(/^### (.+)$/gm, '<h3>$1</h3>')
                .replace(/^## (.+)$/gm, '<h2>$1</h2>')
                .replace(/^# (.+)$/gm, '<h1>$1</h1>')
                .replace(/\*\*(.+?)\*\*/g, '<strong>$1</strong>')
                .replace(/\*(.+?)\*/g, '<em>$1</em>')
                .replace(/`(.+?)`/g, '<code>$1</code>')
                .replace(/^> (.+)$/gm, '<blockquote>$1</blockquote>')
                .replace(/^- (.+)$/gm, '<li>$1</li>')
                .replace(/(<li>.*<\/li>\n?)+/g, '<ul>$&</ul>')
                .replace(/\n\n/g, '</p><p>')
                .replace(/\n/g, '<br>');
        }

        // ============================================
        // PDF EXTRACTION
        // ============================================
        async function extractTextFromPDF(file) {
            return new Promise(async (resolve, reject) => {
                try {
                    const arrayBuffer = await file.arrayBuffer();
                    pdfjsLib.GlobalWorkerOptions.workerSrc = 'https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js';
                    
                    const pdf = await pdfjsLib.getDocument({ data: arrayBuffer }).promise;
                    let fullText = '';
                    
                    for (let i = 1; i <= pdf.numPages; i++) {
                        const page = await pdf.getPage(i);
                        const textContent = await page.getTextContent();
                        const pageText = textContent.items.map(item => item.str).join(' ');
                        fullText += pageText + '\n\n';
                        
                        // Update progress
                        const progress = Math.round((i / pdf.numPages) * 50);
                        updateProcessingProgress(progress, `Extracting page ${i}/${pdf.numPages}...`);
                    }
                    
                    resolve(fullText.trim());
                } catch (error) {
                    reject(error);
                }
            });
        }

        // ============================================
        // EMBEDDING & VECTOR STORE
        // ============================================
        
        // Generate embedding - returns Float32Array directly
        async function generateEmbedding(text) {
            if (!state.embeddingPipeline) {
                throw new Error('Embedding model not loaded');
            }
            
            const result = await state.embeddingPipeline(text, {
                pooling: 'mean',
                normalize: true
            });
            
            // Keep as Float32Array for faster math operations
            return new Float32Array(result.data);
        }
        
        // Batch generate embeddings for multiple texts
        async function generateEmbeddingsBatch(texts, batchSize = 8) {
            if (!state.embeddingPipeline) {
                throw new Error('Embedding model not loaded');
            }
            
            const embeddings = [];
            
            for (let i = 0; i < texts.length; i += batchSize) {
                const batch = texts.slice(i, Math.min(i + batchSize, texts.length));
                
                // Process batch in parallel
                const batchResults = await Promise.all(
                    batch.map(text => state.embeddingPipeline(text, {
                        pooling: 'mean',
                        normalize: true
                    }))
                );
                
                // Extract embeddings as Float32Array
                for (const result of batchResults) {
                    embeddings.push(new Float32Array(result.data));
                }
            }
            
            return embeddings;
        }

        async function addToVectorStore(chunks, source) {
            const totalChunks = chunks.length;
            
            // Use batched embedding generation
            updateProcessingProgress(50, `Embedding ${totalChunks} chunks...`);
            
            const batchSize = 8;
            for (let i = 0; i < chunks.length; i += batchSize) {
                const batch = chunks.slice(i, Math.min(i + batchSize, chunks.length));
                const embeddings = await generateEmbeddingsBatch(batch, batchSize);
                
                // Add to store
                for (let j = 0; j < batch.length; j++) {
                    state.vectorStore.push({
                        text: batch[j],
                        embedding: embeddings[j],
                        source: source,
                        id: `${source}-${i + j}`
                    });
                }
                
                // Update progress
                const progress = 50 + Math.round(((i + batch.length) / totalChunks) * 50);
                updateProcessingProgress(progress, `Embedded ${Math.min(i + batchSize, totalChunks)}/${totalChunks} chunks...`);
            }
            
            updateMemoryDisplay();
        }

        // Optimized search with partial sort for top-K
        function searchVectorStore(queryEmbedding, topK = CONFIG.TOP_K) {
            const len = state.vectorStore.length;
            if (len === 0) return [];
            
            // Calculate all similarities first
            const scored = new Array(len);
            for (let i = 0; i < len; i++) {
                scored[i] = {
                    index: i,
                    similarity: cosineSimilarity(queryEmbedding, state.vectorStore[i].embedding)
                };
            }
            
            // Partial sort - only find top K (more efficient than full sort)
            for (let i = 0; i < Math.min(topK, len); i++) {
                let maxIdx = i;
                for (let j = i + 1; j < len; j++) {
                    if (scored[j].similarity > scored[maxIdx].similarity) {
                        maxIdx = j;
                    }
                }
                if (maxIdx !== i) {
                    [scored[i], scored[maxIdx]] = [scored[maxIdx], scored[i]];
                }
            }
            
            // Return top K with full data
            return scored.slice(0, topK).map(s => ({
                ...state.vectorStore[s.index],
                similarity: s.similarity
            }));
        }

        // ============================================
        // UI UPDATES
        // ============================================
        function updateMemoryDisplay() {
            const uniqueDocs = new Set(state.vectorStore.map(v => v.source));
            document.getElementById('doc-count').textContent = uniqueDocs.size;
            document.getElementById('chunk-count').textContent = state.vectorStore.length;
            document.getElementById('vector-count').textContent = state.vectorStore.length;
            
            // Estimate storage size
            const size = JSON.stringify(state.vectorStore).length;
            document.getElementById('storage-size').textContent = formatBytes(size);
            
            // Update document list
            const docList = document.getElementById('document-list');
            if (uniqueDocs.size === 0) {
                docList.innerHTML = '<p class="text-sm text-slate-500 italic">No documents loaded yet</p>';
            } else {
                docList.innerHTML = Array.from(uniqueDocs).map(doc => {
                    const chunkCount = state.vectorStore.filter(v => v.source === doc).length;
                    return `
                        <div class="flex items-center justify-between bg-slate-700/50 rounded-lg px-3 py-2">
                            <div class="flex items-center gap-2 overflow-hidden">
                                <i class="fas fa-file-pdf text-red-400 flex-shrink-0"></i>
                                <span class="text-sm text-slate-300 truncate">${doc}</span>
                            </div>
                            <span class="text-xs text-slate-500 flex-shrink-0">${chunkCount} chunks</span>
                        </div>
                    `;
                }).join('');
            }
        }

        function updateProcessingProgress(percent, text) {
            document.getElementById('processing-bar').style.width = `${percent}%`;
            document.getElementById('processing-text').textContent = text;
        }

        function showProcessing(show) {
            document.getElementById('processing-status').classList.toggle('hidden', !show);
        }

        function addMessage(role, content, sources = []) {
            const chatMessages = document.getElementById('chat-messages');
            const messageDiv = document.createElement('div');
            messageDiv.className = 'flex gap-3';
            
            const isUser = role === 'user';
            const avatar = isUser 
                ? '<div class="w-8 h-8 rounded-full bg-gradient-to-br from-green-500 to-teal-500 flex items-center justify-center flex-shrink-0"><i class="fas fa-user text-white text-sm"></i></div>'
                : '<div class="w-8 h-8 rounded-full bg-gradient-to-br from-purple-500 to-blue-500 flex items-center justify-center flex-shrink-0"><i class="fas fa-robot text-white text-sm"></i></div>';
            
            const bgColor = isUser ? 'bg-blue-600/20' : 'bg-slate-700/50';
            const roundedClass = isUser ? 'rounded-tr-none' : 'rounded-tl-none';
            
            let sourcesHtml = '';
            if (sources.length > 0 && !isUser) {
                const uniqueSources = [...new Set(sources.map(s => s.source))];
                sourcesHtml = `
                    <div class="mt-3 pt-3 border-t border-slate-600">
                        <div class="text-xs text-slate-400 mb-2">
                            <i class="fas fa-quote-left mr-1"></i>Sources used:
                        </div>
                        <div class="flex flex-wrap gap-2">
                            ${uniqueSources.map(s => `
                                <span class="px-2 py-1 bg-slate-600/50 rounded text-xs text-slate-300">
                                    <i class="fas fa-file-pdf text-red-400 mr-1"></i>${s}
                                </span>
                            `).join('')}
                        </div>
                    </div>
                `;
            }
            
            messageDiv.innerHTML = `
                ${avatar}
                <div class="${bgColor} rounded-lg ${roundedClass} p-4 max-w-2xl prose text-slate-200">
                    ${isUser ? content : markdownToHtml(content)}
                    ${sourcesHtml}
                </div>
            `;
            
            chatMessages.appendChild(messageDiv);
            chatMessages.scrollTop = chatMessages.scrollHeight;
        }

        function showTypingIndicator() {
            const chatMessages = document.getElementById('chat-messages');
            const typingDiv = document.createElement('div');
            typingDiv.id = 'typing-indicator';
            typingDiv.className = 'flex gap-3';
            typingDiv.innerHTML = `
                <div class="w-8 h-8 rounded-full bg-gradient-to-br from-purple-500 to-blue-500 flex items-center justify-center flex-shrink-0">
                    <i class="fas fa-robot text-white text-sm"></i>
                </div>
                <div class="bg-slate-700/50 rounded-lg rounded-tl-none p-4">
                    <div class="flex gap-1">
                        <div class="w-2 h-2 bg-slate-400 rounded-full typing-dot"></div>
                        <div class="w-2 h-2 bg-slate-400 rounded-full typing-dot"></div>
                        <div class="w-2 h-2 bg-slate-400 rounded-full typing-dot"></div>
                    </div>
                </div>
            `;
            chatMessages.appendChild(typingDiv);
            chatMessages.scrollTop = chatMessages.scrollHeight;
        }

        function hideTypingIndicator() {
            const indicator = document.getElementById('typing-indicator');
            if (indicator) indicator.remove();
        }

        function showContextPanel(chunks) {
            const panel = document.getElementById('context-panel');
            const container = document.getElementById('context-chunks');
            
            container.innerHTML = chunks.map((chunk, i) => `
                <div class="bg-slate-700/50 rounded p-2 text-xs">
                    <div class="flex items-center justify-between mb-1">
                        <span class="text-blue-400 font-medium">${chunk.source}</span>
                        <span class="text-slate-500">${(chunk.similarity * 100).toFixed(1)}% match</span>
                    </div>
                    <p class="text-slate-400 line-clamp-2">${chunk.text.substring(0, 150)}...</p>
                </div>
            `).join('');
            
            panel.classList.remove('hidden');
        }

        // ============================================
        // MODEL LOADING
        // ============================================
        async function checkWebGPU() {
            const statusEl = document.getElementById('webgpu-status');
            
            if (!navigator.gpu) {
                statusEl.innerHTML = `
                    <span class="w-2 h-2 rounded-full bg-red-500"></span>
                    <span class="text-red-400">WebGPU not supported</span>
                `;
                return false;
            }
            
            try {
                const adapter = await navigator.gpu.requestAdapter();
                if (!adapter) {
                    statusEl.innerHTML = `
                        <span class="w-2 h-2 rounded-full bg-red-500"></span>
                        <span class="text-red-400">No GPU adapter found</span>
                    `;
                    return false;
                }
                
                statusEl.innerHTML = `
                    <span class="w-2 h-2 rounded-full bg-green-500"></span>
                    <span class="text-green-400">WebGPU Ready</span>
                `;
                return true;
            } catch (e) {
                statusEl.innerHTML = `
                    <span class="w-2 h-2 rounded-full bg-red-500"></span>
                    <span class="text-red-400">WebGPU error</span>
                `;
                return false;
            }
        }

        async function loadModels() {
            const modelStatus = document.getElementById('model-status');
            const modelIndicator = document.getElementById('model-indicator');
            const modelText = document.getElementById('model-text');
            const modelProgress = document.getElementById('model-progress');
            const progressBar = document.getElementById('model-progress-bar');
            const progressText = document.getElementById('model-progress-text');
            const progressPercent = document.getElementById('model-progress-percent');
            const loadBtn = document.getElementById('load-models-btn');
            
            loadBtn.disabled = true;
            loadBtn.innerHTML = '<i class="fas fa-spinner fa-spin mr-1"></i>Loading...';
            modelProgress.classList.remove('hidden');
            
            try {
                // Load Transformers.js for embeddings
                progressText.textContent = 'Loading Transformers.js...';
                progressPercent.textContent = '5%';
                progressBar.style.width = '5%';
                
                const { pipeline } = await import('https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.1');
                
                // Store pipeline factory for lazy loading Whisper later
                state.pipelineFactory = pipeline;
                
                progressText.textContent = 'Loading embedding model...';
                progressPercent.textContent = '15%';
                progressBar.style.width = '15%';
                
                state.embeddingPipeline = await pipeline('feature-extraction', CONFIG.EMBEDDING_MODEL, {
                    progress_callback: (progress) => {
                        if (progress.status === 'progress') {
                            const pct = Math.round(15 + (progress.progress * 0.25));
                            progressPercent.textContent = `${pct}%`;
                            progressBar.style.width = `${pct}%`;
                        }
                    }
                });
                
                // Skip Whisper for now - will lazy load on first mic click
                // This saves ~30% of initial load time
                progressText.textContent = 'Whisper STT will load on first use...';
                progressPercent.textContent = '40%';
                progressBar.style.width = '40%';
                
                // Load WebLLM
                progressText.textContent = 'Loading WebLLM...';
                progressPercent.textContent = '45%';
                progressBar.style.width = '45%';
                
                const webllm = await import('https://esm.run/@mlc-ai/web-llm');
                
                progressText.textContent = 'Loading LLM model (this may take a while)...';
                
                state.llmEngine = await webllm.CreateMLCEngine(CONFIG.LLM_MODEL, {
                    initProgressCallback: (progress) => {
                        const pct = Math.round(45 + (progress.progress * 55));
                        progressPercent.textContent = `${pct}%`;
                        progressBar.style.width = `${pct}%`;
                        progressText.textContent = progress.text || 'Loading LLM...';
                    }
                });
                
                // Success!
                state.modelsLoaded = true;
                modelIndicator.className = 'w-3 h-3 rounded-full bg-green-500';
                modelText.textContent = 'Models ready!';
                modelText.className = 'text-sm text-green-400';
                modelProgress.classList.add('hidden');
                loadBtn.classList.add('hidden');
                
                // Enable chat
                document.getElementById('user-input').disabled = false;
                document.getElementById('send-btn').disabled = false;
                
                addMessage('assistant', 'Models loaded successfully! ðŸŽ‰ I\'m ready to help you analyze your research papers. Upload some PDFs and ask me anything!\n\nðŸŽ¤ **Voice input available** - Click the microphone (Whisper loads on first use).');
                
            } catch (error) {
                console.error('Error loading models:', error);
                modelIndicator.className = 'w-3 h-3 rounded-full bg-red-500';
                modelText.textContent = 'Error loading models';
                modelText.className = 'text-sm text-red-400';
                progressText.textContent = error.message;
                loadBtn.disabled = false;
                loadBtn.innerHTML = '<i class="fas fa-redo mr-1"></i>Retry';
                
                addMessage('assistant', `âŒ Error loading models: ${error.message}\n\nPlease make sure you're using a browser with WebGPU support (Chrome 113+ or Edge 113+).`);
            }
        }
        
        // Lazy load Whisper when needed
        async function ensureWhisperLoaded() {
            if (state.whisperPipeline) return true;
            if (!state.pipelineFactory) return false;
            
            try {
                addMessage('assistant', 'ðŸŽ¤ Loading Whisper STT model for the first time...');
                state.whisperPipeline = await state.pipelineFactory('automatic-speech-recognition', CONFIG.WHISPER_MODEL);
                addMessage('assistant', 'âœ… Whisper ready! You can now use voice input.');
                return true;
            } catch (error) {
                console.error('Error loading Whisper:', error);
                addMessage('assistant', `âŒ Failed to load Whisper: ${error.message}`);
                return false;
            }
        }

        // ============================================
        // CHAT LOGIC
        // ============================================
        async function handleChat(userMessage) {
            if (!state.modelsLoaded || state.isGenerating) return;
            
            state.isGenerating = true;
            const sendBtn = document.getElementById('send-btn');
            const userInput = document.getElementById('user-input');
            sendBtn.disabled = true;
            userInput.disabled = true;
            
            // Initialize metrics for this query
            const queryId = 'q-' + Date.now();
            const queryStartTime = performance.now();
            let ttftMs = 0;
            let firstTokenReceived = false;
            let tokensGenerated = 0;
            
            // Add user message
            addMessage('user', userMessage);
            state.chatHistory.push({ role: 'user', content: userMessage });
            
            showTypingIndicator();
            
            try {
                // Get relevant context from vector store
                let relevantChunks = [];
                let contextText = '';
                let retrievalMetrics = { topSimilarity: 0, avgSimilarity: 0, sourceDiversity: 0, searchTimeMs: 0 };
                
                if (state.vectorStore.length > 0) {
                    const searchStart = performance.now();
                    const queryEmbedding = await generateEmbedding(userMessage);
                    const topK = parseInt(document.getElementById('top-k').value);
                    relevantChunks = searchVectorStore(queryEmbedding, topK);
                    retrievalMetrics.searchTimeMs = Math.round(performance.now() - searchStart);
                    
                    if (relevantChunks.length > 0) {
                        showContextPanel(relevantChunks);
                        contextText = relevantChunks.map((chunk, i) => 
                            `[Source: ${chunk.source}]\n${chunk.text}`
                        ).join('\n\n---\n\n');
                        
                        // Calculate retrieval metrics
                        retrievalMetrics.topSimilarity = relevantChunks[0].similarity;
                        retrievalMetrics.avgSimilarity = relevantChunks.reduce((sum, c) => sum + c.similarity, 0) / relevantChunks.length;
                        retrievalMetrics.sourceDiversity = new Set(relevantChunks.map(c => c.source)).size;
                    }
                }
                
                // Build prompt
                const systemPrompt = document.getElementById('system-prompt').value;
                const temperature = parseFloat(document.getElementById('temperature').value);
                
                // Combine system prompt with context (WebLLM only allows ONE system message at the start)
                let fullSystemPrompt = systemPrompt;
                if (contextText) {
                    fullSystemPrompt += `\n\n---\n\nHere are relevant excerpts from the uploaded research papers:\n\n${contextText}\n\nUse this context to answer the user's question. Always cite which paper/source you're referencing.`;
                }
                
                let messages = [
                    { role: 'system', content: fullSystemPrompt }
                ];
                
                // Add chat history (last 6 messages for context window management)
                const recentHistory = state.chatHistory.slice(-6);
                messages = messages.concat(recentHistory);
                
                // Generate response
                const generationStart = performance.now();
                const response = await state.llmEngine.chat.completions.create({
                    messages: messages,
                    temperature: temperature,
                    max_tokens: 1024,
                    stream: true
                });
                
                hideTypingIndicator();
                
                // Stream the response
                let fullResponse = '';
                const chatMessages = document.getElementById('chat-messages');
                
                // Create message container with unique ID
                const messageId = 'msg-' + Date.now();
                const messageDiv = document.createElement('div');
                messageDiv.className = 'flex gap-3';
                messageDiv.innerHTML = `
                    <div class="w-8 h-8 rounded-full bg-gradient-to-br from-purple-500 to-blue-500 flex items-center justify-center flex-shrink-0">
                        <i class="fas fa-robot text-white text-sm"></i>
                    </div>
                    <div class="bg-slate-700/50 rounded-lg rounded-tl-none p-4 max-w-2xl prose text-slate-200">
                        <span id="${messageId}"></span>
                    </div>
                `;
                chatMessages.appendChild(messageDiv);
                
                const streamingContent = document.getElementById(messageId);
                
                for await (const chunk of response) {
                    // Track TTFT (Time To First Token)
                    if (!firstTokenReceived) {
                        ttftMs = Math.round(performance.now() - generationStart);
                        firstTokenReceived = true;
                    }
                    
                    const delta = chunk.choices[0]?.delta?.content || '';
                    if (delta) tokensGenerated++;
                    fullResponse += delta;
                    streamingContent.innerHTML = markdownToHtml(fullResponse);
                    chatMessages.scrollTop = chatMessages.scrollHeight;
                }
                
                const totalTimeMs = Math.round(performance.now() - queryStartTime);
                const generationTimeMs = Math.round(performance.now() - generationStart);
                const tokensPerSecond = generationTimeMs > 0 ? Math.round((tokensGenerated / generationTimeMs) * 1000) : 0;
                
                // Add sources and feedback buttons to the message
                const uniqueSources = relevantChunks.length > 0 ? [...new Set(relevantChunks.map(s => s.source))] : [];
                const sourcesHtml = uniqueSources.length > 0 ? `
                    <div class="mt-3 pt-3 border-t border-slate-600">
                        <div class="text-xs text-slate-400 mb-2">
                            <i class="fas fa-quote-left mr-1"></i>Sources used:
                        </div>
                        <div class="flex flex-wrap gap-2">
                            ${uniqueSources.map(s => `
                                <span class="px-2 py-1 bg-slate-600/50 rounded text-xs text-slate-300">
                                    <i class="fas fa-file-pdf text-red-400 mr-1"></i>${s}
                                </span>
                            `).join('')}
                        </div>
                    </div>
                ` : '';
                
                // Add feedback buttons
                const feedbackHtml = `
                    <div class="mt-3 pt-3 border-t border-slate-600 flex items-center justify-between">
                        <div class="text-xs text-slate-500">
                            <i class="fas fa-tachometer-alt mr-1"></i>
                            TTFT: ${ttftMs}ms | ${tokensPerSecond} tok/s | Total: ${(totalTimeMs/1000).toFixed(1)}s
                        </div>
                        <div class="flex items-center gap-2" id="feedback-${queryId}">
                            <span class="text-xs text-slate-500">Helpful?</span>
                            <button onclick="window.recordFeedback('${queryId}', 'up')" class="feedback-btn p-1.5 rounded hover:bg-green-600/30 text-slate-400 hover:text-green-400 transition-colors" title="Yes, helpful">
                                <i class="fas fa-thumbs-up"></i>
                            </button>
                            <button onclick="window.recordFeedback('${queryId}', 'down')" class="feedback-btn p-1.5 rounded hover:bg-red-600/30 text-slate-400 hover:text-red-400 transition-colors" title="Not helpful">
                                <i class="fas fa-thumbs-down"></i>
                            </button>
                        </div>
                    </div>
                `;
                
                messageDiv.querySelector('.prose').innerHTML += sourcesHtml + feedbackHtml;
                streamingContent.removeAttribute('id');
                
                // Add to history
                state.chatHistory.push({ role: 'assistant', content: fullResponse });
                
                // Store query metrics
                const queryMetrics = {
                    id: queryId,
                    timestamp: Date.now(),
                    query: userMessage.substring(0, 200),
                    retrieval: retrievalMetrics,
                    generation: {
                        ttftMs,
                        totalTimeMs,
                        generationTimeMs,
                        tokensGenerated,
                        tokensPerSecond
                    },
                    feedback: null,
                    selfEval: null
                };
                state.queriesMetrics.push(queryMetrics);
                
                // Save to Firebase (or localStorage fallback)
                saveQueryMetrics(queryMetrics);
                
                // Run self-evaluation in background (don't await)
                runSelfEvaluation(queryId, userMessage, contextText, fullResponse);
                
                // TTS if enabled (using browser's SpeechSynthesis)
                if (CONFIG.TTS_ENABLED && window.speechSynthesis && fullResponse.length < 800) {
                    window.speechSynthesis.cancel();
                    const cleanText = fullResponse
                        .replace(/\*\*/g, '')
                        .replace(/\*/g, '')
                        .replace(/#{1,3}\s/g, '')
                        .replace(/`/g, '')
                        .substring(0, 500);
                    const utterance = new SpeechSynthesisUtterance(cleanText);
                    utterance.rate = 1.0;
                    utterance.pitch = 1.0;
                    window.speechSynthesis.speak(utterance);
                }
                
            } catch (error) {
                console.error('Chat error:', error);
                hideTypingIndicator();
                addMessage('assistant', `âŒ Error generating response: ${error.message}`);
            }
            
            state.isGenerating = false;
            sendBtn.disabled = false;
            userInput.disabled = false;
            userInput.focus();
        }
        
        // Expose recordFeedback to window for onclick handlers
        window.recordFeedback = function(queryId, vote) {
            recordFeedback(queryId, vote);
            
            // Update UI to show feedback was recorded
            const feedbackDiv = document.getElementById(`feedback-${queryId}`);
            if (feedbackDiv) {
                const isUp = vote === 'up';
                feedbackDiv.innerHTML = `
                    <span class="text-xs ${isUp ? 'text-green-400' : 'text-red-400'}">
                        <i class="fas fa-${isUp ? 'thumbs-up' : 'thumbs-down'} mr-1"></i>
                        ${isUp ? 'Thanks for the feedback!' : 'Thanks, we\'ll improve!'}
                    </span>
                `;
            }
        };

        // ============================================
        // EVENT LISTENERS
        // ============================================
        document.addEventListener('DOMContentLoaded', async () => {
            // Initialize metrics storage (don't wait, let it run in background)
            initMetricsStorage().catch(e => console.warn('Metrics init:', e));
            
            // Check WebGPU
            await checkWebGPU();
            
            // File upload
            const dropZone = document.getElementById('drop-zone');
            const fileInput = document.getElementById('file-input');
            
            dropZone.addEventListener('click', () => fileInput.click());
            
            dropZone.addEventListener('dragover', (e) => {
                e.preventDefault();
                dropZone.classList.add('border-blue-500', 'bg-slate-700/50');
            });
            
            dropZone.addEventListener('dragleave', () => {
                dropZone.classList.remove('border-blue-500', 'bg-slate-700/50');
            });
            
            dropZone.addEventListener('drop', async (e) => {
                e.preventDefault();
                dropZone.classList.remove('border-blue-500', 'bg-slate-700/50');
                const files = Array.from(e.dataTransfer.files).filter(f => f.type === 'application/pdf');
                await processFiles(files);
            });
            
            fileInput.addEventListener('change', async (e) => {
                const files = Array.from(e.target.files);
                await processFiles(files);
                e.target.value = '';
            });
            
            async function processFiles(files) {
                if (files.length === 0) return;
                if (!state.embeddingPipeline) {
                    addMessage('assistant', 'âš ï¸ Please load the models first before uploading documents.');
                    return;
                }
                if (state.isProcessing) return;
                
                state.isProcessing = true;
                showProcessing(true);
                
                for (const file of files) {
                    try {
                        updateProcessingProgress(0, `Processing ${file.name}...`);
                        
                        // Extract text
                        const text = await extractTextFromPDF(file);
                        
                        if (text.trim().length < 100) {
                            addMessage('assistant', `âš ï¸ Could not extract meaningful text from ${file.name}. The PDF might be image-based.`);
                            continue;
                        }
                        
                        // Chunk text
                        const chunks = chunkText(text);
                        
                        // Add to vector store
                        await addToVectorStore(chunks, file.name);
                        
                        state.documents.push({
                            name: file.name,
                            chunkCount: chunks.length,
                            textLength: text.length
                        });
                        
                        addMessage('assistant', `âœ… Successfully processed **${file.name}**\n- Extracted ${text.length.toLocaleString()} characters\n- Created ${chunks.length} chunks\n- Generated ${chunks.length} embeddings`);
                        
                    } catch (error) {
                        console.error(`Error processing ${file.name}:`, error);
                        addMessage('assistant', `âŒ Error processing ${file.name}: ${error.message}`);
                    }
                }
                
                showProcessing(false);
                state.isProcessing = false;
            }
            
            // Load models button
            document.getElementById('load-models-btn').addEventListener('click', loadModels);
            
            // AUTO-LOAD: Start loading models immediately
            console.log('ðŸš€ Auto-loading models...');
            loadModels();
            
            // Clear memory
            document.getElementById('clear-memory').addEventListener('click', () => {
                state.vectorStore = [];
                state.documents = [];
                updateMemoryDisplay();
                addMessage('assistant', 'ðŸ—‘ï¸ Memory cleared. All documents have been removed.');
            });
            
            // Temperature slider
            document.getElementById('temperature').addEventListener('input', (e) => {
                document.getElementById('temp-value').textContent = e.target.value;
                CONFIG.TEMPERATURE = parseFloat(e.target.value);
            });
            
            // Top K slider
            document.getElementById('top-k').addEventListener('input', (e) => {
                document.getElementById('topk-value').textContent = e.target.value;
                CONFIG.TOP_K = parseInt(e.target.value);
            });
            
            // TTS Toggle
            const ttsToggle = document.getElementById('tts-toggle');
            ttsToggle.addEventListener('click', () => {
                CONFIG.TTS_ENABLED = !CONFIG.TTS_ENABLED;
                const toggleKnob = ttsToggle.querySelector('span');
                if (CONFIG.TTS_ENABLED) {
                    ttsToggle.classList.remove('bg-slate-600');
                    ttsToggle.classList.add('bg-green-600');
                    toggleKnob.classList.add('translate-x-6');
                } else {
                    ttsToggle.classList.remove('bg-green-600');
                    ttsToggle.classList.add('bg-slate-600');
                    toggleKnob.classList.remove('translate-x-6');
                    window.speechSynthesis.cancel(); // Stop any ongoing speech
                }
            });
            
            // Chat input
            const userInput = document.getElementById('user-input');
            const sendBtn = document.getElementById('send-btn');
            
            userInput.addEventListener('input', () => {
                document.getElementById('char-count').textContent = `${userInput.value.length} / 2000`;
            });
            
            userInput.addEventListener('keydown', (e) => {
                if (e.key === 'Enter' && !e.shiftKey) {
                    e.preventDefault();
                    if (userInput.value.trim() && !sendBtn.disabled) {
                        handleChat(userInput.value.trim());
                        userInput.value = '';
                        document.getElementById('char-count').textContent = '0 / 2000';
                    }
                }
            });
            
            sendBtn.addEventListener('click', () => {
                if (userInput.value.trim()) {
                    handleChat(userInput.value.trim());
                    userInput.value = '';
                    document.getElementById('char-count').textContent = '0 / 2000';
                }
            });
            
            // Close context panel
            document.getElementById('close-context').addEventListener('click', () => {
                document.getElementById('context-panel').classList.add('hidden');
            });
            
            // TTS Function - Read response aloud
            function speakText(text) {
                if (!CONFIG.TTS_ENABLED || !window.speechSynthesis) return;
                
                // Cancel any ongoing speech
                window.speechSynthesis.cancel();
                
                // Clean text for speech (remove markdown)
                const cleanText = text
                    .replace(/\*\*/g, '')
                    .replace(/\*/g, '')
                    .replace(/#{1,3}\s/g, '')
                    .replace(/`/g, '')
                    .substring(0, 500); // Limit length
                
                const utterance = new SpeechSynthesisUtterance(cleanText);
                utterance.rate = 1.0;
                utterance.pitch = 1.0;
                window.speechSynthesis.speak(utterance);
            }
            
            // Voice input with Whisper STT
            const voiceBtn = document.getElementById('voice-btn');
            const voiceIndicator = document.getElementById('voice-indicator');
            let mediaRecorder = null;
            let audioChunks = [];
            let isRecording = false;
            
            voiceBtn.addEventListener('click', async () => {
                if (!state.modelsLoaded) {
                    addMessage('assistant', 'âš ï¸ Please load the models first.');
                    return;
                }
                
                if (state.isTranscribing) {
                    return; // Already transcribing
                }
                
                // If recording, stop and transcribe
                if (isRecording && mediaRecorder) {
                    mediaRecorder.stop();
                    return;
                }
                
                // Lazy load Whisper on first use
                if (!state.whisperPipeline) {
                    voiceBtn.disabled = true;
                    const loaded = await ensureWhisperLoaded();
                    voiceBtn.disabled = false;
                    if (!loaded) return;
                }
                
                // Start recording
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            sampleRate: 16000,
                            channelCount: 1
                        }
                    });
                    
                    mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
                    audioChunks = [];
                    isRecording = true;
                    
                    mediaRecorder.ondataavailable = (e) => {
                        if (e.data.size > 0) {
                            audioChunks.push(e.data);
                        }
                    };
                    
                    mediaRecorder.onstop = async () => {
                        isRecording = false;
                        stream.getTracks().forEach(track => track.stop());
                        voiceIndicator.querySelector('span').textContent = 'Transcribing...';
                        voiceBtn.classList.remove('text-red-500');
                        voiceBtn.classList.add('text-yellow-500');
                        state.isTranscribing = true;
                        
                        try {
                            // Convert to blob
                            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                            
                            // Convert blob to audio buffer using Web Audio API
                            const audioContext = new AudioContext({ sampleRate: 16000 });
                            const arrayBuffer = await audioBlob.arrayBuffer();
                            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                            
                            // Get Float32Array from the audio buffer (mono, 16kHz)
                            let audioData;
                            if (audioBuffer.numberOfChannels > 1) {
                                // Mix stereo to mono
                                const left = audioBuffer.getChannelData(0);
                                const right = audioBuffer.getChannelData(1);
                                audioData = new Float32Array(left.length);
                                for (let i = 0; i < left.length; i++) {
                                    audioData[i] = (left[i] + right[i]) / 2;
                                }
                            } else {
                                audioData = audioBuffer.getChannelData(0);
                            }
                            
                            // Resample to 16kHz if needed
                            const targetSampleRate = 16000;
                            if (audioBuffer.sampleRate !== targetSampleRate) {
                                const ratio = audioBuffer.sampleRate / targetSampleRate;
                                const newLength = Math.round(audioData.length / ratio);
                                const resampled = new Float32Array(newLength);
                                for (let i = 0; i < newLength; i++) {
                                    const srcIdx = Math.floor(i * ratio);
                                    resampled[i] = audioData[srcIdx];
                                }
                                audioData = resampled;
                            }
                            
                            await audioContext.close();
                            
                            // Transcribe with Whisper (English)
                            if (state.whisperPipeline) {
                                const result = await state.whisperPipeline(audioData, {
                                    language: 'english',
                                    task: 'transcribe'
                                });
                                const transcription = result.text.trim();
                                
                                voiceIndicator.classList.add('hidden');
                                voiceBtn.classList.remove('text-yellow-500');
                                state.isTranscribing = false;
                                
                                if (transcription && transcription.length > 0) {
                                    // Put transcription in input field
                                    const userInput = document.getElementById('user-input');
                                    userInput.value = transcription;
                                    document.getElementById('char-count').textContent = `${transcription.length} / 2000`;
                                    
                                    // Auto-send the message
                                    handleChat(transcription);
                                    userInput.value = '';
                                    document.getElementById('char-count').textContent = '0 / 2000';
                                } else {
                                    addMessage('assistant', 'ðŸŽ¤ Could not detect any speech. Please try again.');
                                }
                            }
                        } catch (error) {
                            console.error('Transcription error:', error);
                            voiceIndicator.classList.add('hidden');
                            voiceBtn.classList.remove('text-yellow-500');
                            state.isTranscribing = false;
                            addMessage('assistant', `âŒ Transcription error: ${error.message}`);
                        }
                    };
                    
                    mediaRecorder.start();
                    voiceIndicator.classList.remove('hidden');
                    voiceIndicator.querySelector('span').textContent = 'Listening...';
                    voiceBtn.classList.add('text-red-500');
                    
                    // Auto-stop after 15 seconds
                    setTimeout(() => {
                        if (mediaRecorder && mediaRecorder.state === 'recording') {
                            mediaRecorder.stop();
                        }
                    }, 15000);
                    
                } catch (error) {
                    console.error('Microphone error:', error);
                    addMessage('assistant', 'âŒ Could not access microphone. Please check permissions.');
                }
            });
        });
    </script>
</body>
</html>